{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60017e2c-3d6f-48d4-9fa3-bacb44722332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078a5d4-839c-4b73-9cb4-aed5d1d39a77",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandit related Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb957b9c-e6f8-4bb8-86ab-5746128591a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "# Abstract Arm class\n",
    "class Arm(ABC):\n",
    "    @abstractmethod\n",
    "    def pull(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def mean(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "# NormalArm: Gaussian distributed rewards\n",
    "class NormalArm(Arm):\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.total_reward = 0.0\n",
    "        self.pull_count = 0\n",
    "\n",
    "    def pull(self):\n",
    "        reward = np.random.normal(self.mu, self.sigma)\n",
    "        self.total_reward += reward\n",
    "        self.pull_count += 1\n",
    "        return reward\n",
    "\n",
    "    def mean(self):\n",
    "        return self.mu\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0.0\n",
    "        self.pull_count = 0\n",
    "\n",
    "\n",
    "# DiscreteArm: Sample from a discrete distribution\n",
    "class DiscreteArm(Arm):\n",
    "    def __init__(self, rewards, probabilities):\n",
    "        assert len(rewards) == len(probabilities), \"Mismatched reward-probability lengths\"\n",
    "        assert np.isclose(sum(probabilities), 1.0), \"Probabilities must sum to 1\"\n",
    "        self.rewards = rewards\n",
    "        self.probabilities = probabilities\n",
    "        self.total_reward = 0.0\n",
    "        self.pull_count = 0\n",
    "\n",
    "    def pull(self):\n",
    "        reward = np.random.choice(self.rewards, p=self.probabilities)\n",
    "        self.total_reward += reward\n",
    "        self.pull_count += 1\n",
    "        return reward\n",
    "\n",
    "    def mean(self):\n",
    "        return np.dot(self.rewards, self.probabilities)\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0.0\n",
    "        self.pull_count = 0\n",
    "\n",
    "\n",
    "# MultiArmedBandit manager class\n",
    "class MultiArmedBandit:\n",
    "    def __init__(self, arms):\n",
    "        self.arms = arms\n",
    "        self.best_arm_index = np.argmax([arm.mean() for arm in arms])\n",
    "        self.best_mean = self.arms[self.best_arm_index].mean()\n",
    "\n",
    "    def pull(self, index):\n",
    "        return self.arms[index].pull()\n",
    "\n",
    "    def regret(self, reward):\n",
    "        return self.best_mean - reward\n",
    "\n",
    "    def get_best_arm(self):\n",
    "        return self.best_arm_index\n",
    "\n",
    "    def reset_all(self):\n",
    "        for arm in self.arms:\n",
    "            arm.reset()\n",
    "\n",
    "    def all_means(self):\n",
    "        return [arm.mean() for arm in self.arms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8fa3a5-b56d-47d9-bbe1-e2cb661c49c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0: Pulled arm 2, reward=2.27, regret=0.23\n",
      "Round 1: Pulled arm 0, reward=-0.25, regret=2.75\n",
      "Round 2: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 3: Pulled arm 0, reward=0.47, regret=2.03\n",
      "Round 4: Pulled arm 0, reward=1.00, regret=1.50\n",
      "Round 5: Pulled arm 2, reward=2.74, regret=-0.24\n",
      "Round 6: Pulled arm 0, reward=2.23, regret=0.27\n",
      "Round 7: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 8: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 9: Pulled arm 0, reward=0.33, regret=2.17\n",
      "Round 10: Pulled arm 0, reward=0.83, regret=1.67\n",
      "Round 11: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 12: Pulled arm 0, reward=1.52, regret=0.98\n",
      "Round 13: Pulled arm 0, reward=-0.40, regret=2.90\n",
      "Round 14: Pulled arm 0, reward=-0.41, regret=2.91\n",
      "Round 15: Pulled arm 0, reward=1.26, regret=1.24\n",
      "Round 16: Pulled arm 2, reward=2.23, regret=0.27\n",
      "Round 17: Pulled arm 2, reward=2.76, regret=-0.26\n",
      "Round 18: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 19: Pulled arm 2, reward=1.48, regret=1.02\n",
      "Round 20: Pulled arm 2, reward=3.16, regret=-0.66\n",
      "Round 21: Pulled arm 0, reward=3.89, regret=-1.39\n",
      "Round 22: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 23: Pulled arm 2, reward=1.89, regret=0.61\n",
      "Round 24: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 25: Pulled arm 2, reward=2.53, regret=-0.03\n",
      "Round 26: Pulled arm 0, reward=-0.15, regret=2.65\n",
      "Round 27: Pulled arm 0, reward=1.18, regret=1.32\n",
      "Round 28: Pulled arm 2, reward=2.87, regret=-0.37\n",
      "Round 29: Pulled arm 2, reward=2.76, regret=-0.26\n",
      "Round 30: Pulled arm 2, reward=2.43, regret=0.07\n",
      "Round 31: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 32: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 33: Pulled arm 0, reward=2.05, regret=0.45\n",
      "Round 34: Pulled arm 2, reward=2.34, regret=0.16\n",
      "Round 35: Pulled arm 2, reward=2.66, regret=-0.16\n",
      "Round 36: Pulled arm 2, reward=2.85, regret=-0.35\n",
      "Round 37: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 38: Pulled arm 2, reward=2.48, regret=0.02\n",
      "Round 39: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 40: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 41: Pulled arm 0, reward=0.40, regret=2.10\n",
      "Round 42: Pulled arm 0, reward=2.73, regret=-0.23\n",
      "Round 43: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 44: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 45: Pulled arm 0, reward=1.53, regret=0.97\n",
      "Round 46: Pulled arm 2, reward=2.08, regret=0.42\n",
      "Round 47: Pulled arm 0, reward=0.97, regret=1.53\n",
      "Round 48: Pulled arm 2, reward=2.64, regret=-0.14\n",
      "Round 49: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 50: Pulled arm 0, reward=0.16, regret=2.34\n",
      "Round 51: Pulled arm 0, reward=1.45, regret=1.05\n",
      "Round 52: Pulled arm 2, reward=1.62, regret=0.88\n",
      "Round 53: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 54: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 55: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 56: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 57: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 58: Pulled arm 2, reward=3.53, regret=-1.03\n",
      "Round 59: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 60: Pulled arm 0, reward=-0.81, regret=3.31\n",
      "Round 61: Pulled arm 2, reward=2.53, regret=-0.03\n",
      "Round 62: Pulled arm 0, reward=0.42, regret=2.08\n",
      "Round 63: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 64: Pulled arm 0, reward=0.16, regret=2.34\n",
      "Round 65: Pulled arm 2, reward=2.77, regret=-0.27\n",
      "Round 66: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 67: Pulled arm 2, reward=3.11, regret=-0.61\n",
      "Round 68: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 69: Pulled arm 0, reward=1.44, regret=1.06\n",
      "Round 70: Pulled arm 0, reward=1.17, regret=1.33\n",
      "Round 71: Pulled arm 2, reward=1.68, regret=0.82\n",
      "Round 72: Pulled arm 2, reward=1.93, regret=0.57\n",
      "Round 73: Pulled arm 2, reward=2.40, regret=0.10\n",
      "Round 74: Pulled arm 2, reward=2.24, regret=0.26\n",
      "Round 75: Pulled arm 2, reward=2.23, regret=0.27\n",
      "Round 76: Pulled arm 2, reward=2.92, regret=-0.42\n",
      "Round 77: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 78: Pulled arm 2, reward=2.11, regret=0.39\n",
      "Round 79: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 80: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 81: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 82: Pulled arm 2, reward=2.42, regret=0.08\n",
      "Round 83: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 84: Pulled arm 2, reward=2.82, regret=-0.32\n",
      "Round 85: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 86: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 87: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 88: Pulled arm 0, reward=0.04, regret=2.46\n",
      "Round 89: Pulled arm 0, reward=1.29, regret=1.21\n",
      "Round 90: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Round 91: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 92: Pulled arm 2, reward=1.63, regret=0.87\n",
      "Round 93: Pulled arm 0, reward=2.81, regret=-0.31\n",
      "Round 94: Pulled arm 2, reward=2.12, regret=0.38\n",
      "Round 95: Pulled arm 1, reward=1.00, regret=1.50\n",
      "Round 96: Pulled arm 0, reward=-0.21, regret=2.71\n",
      "Round 97: Pulled arm 1, reward=0.00, regret=2.50\n",
      "Round 98: Pulled arm 0, reward=-0.51, regret=3.01\n",
      "Round 99: Pulled arm 1, reward=5.00, regret=-2.50\n",
      "Best arm is arm 2 with expected mean 2.50\n"
     ]
    }
   ],
   "source": [
    "arms = [\n",
    "    NormalArm(mu=1.0, sigma=1.0),\n",
    "    DiscreteArm(rewards=[0, 1, 5], probabilities=[0.2, 0.5, 0.3]),\n",
    "    NormalArm(mu=2.5, sigma=0.5)\n",
    "]\n",
    "\n",
    "bandit = MultiArmedBandit(arms)\n",
    "\n",
    "for t in range(100):\n",
    "    chosen = np.random.randint(len(arms))\n",
    "    reward = bandit.pull(chosen)\n",
    "    reg = bandit.regret(reward)\n",
    "    print(f\"Round {t}: Pulled arm {chosen}, reward={reward:.2f}, regret={reg:.2f}\")\n",
    "\n",
    "print(f\"Best arm is arm {bandit.get_best_arm()} with expected mean {bandit.best_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7396cf7-4882-487a-84e5-e774c226aa11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
